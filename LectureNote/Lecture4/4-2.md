## 4-2. K-fold Cross Validation (교차 검증)  
training data가 너무 적을 경우, 일부를 validatoin으로 쓰기 곤란함  

if K = 5, 전체 데이터 120개, Train data 80, Test data 20, Validation data 20  
이럴 경우, validation data가 모두 비슷한 data일 경우, 편향 우려가 있음.  
> 1st. **각기 다른 train, validation 조합의 데이터로 5개 모델을 만들자**  
> 2nd. **5개의 validation loss의 평균을 구하자**

3rd. 선택된 set로 training data 전체에 대해 새로 학습시키자 ( 검증 데이터를 쓰지 말자 )  
&nbsp;&nbsp; or 학습했던 5개 모델의 출력 결과를 하나로 합치자 (예: **majority vote**)  

---
