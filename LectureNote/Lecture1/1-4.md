## 1-4. 강화  학습  
보상을 함으로써 어떤 행동을 하게끔 강화  
즉, **행동 → 보상**  

```yaml
Agent: 행동을 취하는 주체 (예: 강아지, 흑돌)
Action: Agent가 취할 수 있는  모든 행동 (예: 손, 뒤집기, 수)
Reward: Agent가 Action에 따라 받게 되는 보상 (예: 간식, 승점)
Envirionment: Reward를 언제, 얼마만큼 줄지 설계된 환경 (예: 주인, 심판, 백돌)
State: 현재 상태 (예: 위치)
Q-function: 특정 State에서 특정 Action을 했을 때 Reward의 기댓값(즉, Q(state, action)에 대한 함수)
Episode: 각각의 시행
Q-learning: 이전 state에서 행동했던 것에 대한 Q값을 업데이트 하는 것 → 가장 큰 값을 가지고 옴
exploration: 예) E-Greedy: 0에서 1까지의 확률로 다른 행동을 하게 함
discount factor(Γ): 0에서 1까지의 값. Q-learning에서 값을 가져올 때 Γ를 곱함.
```
> `Agent`가 `Action`을 통해 랜덤으로 행동해 `Reward`를 받음  
그러면서 `Q-function` 값을 기록하고 `Q-learning`을 하며 이를 반영해 움직임  
  
> 이때, 학습을 어느정도 하면 일정 행동만 할 수 있음  
→ `exploration`

> 그리고 Q값이 같을 때 최적의 행동이 무엇인지를 알려줘야 함  
→ `discount factor(Γ)`


  
Q&A    
Q. Q-fuction에서 지금까지 이동하며 얻은 보상은 포함되는가?  
A. 아니다.  

---
