## 1-3. 자기지도 학습   
지도학습?  
`문제` 정답 데이터들이 많아야 함-> 데이터 레이블링 비용 상당함  
`해결` 자기지도 학습!  
### "진짜 풀려고 했던 문제 말고 가짜 문제를 새롭게 정의해서 먼저 풀어본다"  

예) **1st.** 패치 위치를 랜덤하게 잡는다.  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**2nd.** 같은 사이즈의 패치들을 주변에 상대적인 위치로 찍는다.  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**3rd.** (일반적인 방법) 첫 패치 + 주변 하나 패치 입력-> 상대적인 위치를 출력하도록 학습시킨다.  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**4th.** 3rd를 무한 번 반복  

그렇다면 왜 이게 가능한가?  
픽셀들이 연속되어 있기 때문이다!  

<br>

> ### 자기지도 학습  
데이터 안에서 스스로 레이블(정답)을 만들어서 학습  
<br>
1st. **`pretext task`**(가짜 문제)를 학습해서 **pre-training**  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-> pre-trained model  
2nd. **downstream task**(분류)를 풀기 위해 **transfer learning**(전이 학습)  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-> classification model

|지도 학습|자기지도 학습|
|:--:|:--:|
|2nd|1st 후 2nd|

**[ pretext tast ]**  
TYPE1) **`Context prediction`**(위의 예시 참고)  
TYPE2) **`Contrastive learning`**  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1st. 사진1의 일부를 뗀 사진(1번 사진)을 CNN 모델에 넣은 후 나온 출력(1')  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2nd. 사진1에서 1st를 반복, 2번 사진과 2'  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3rd. 사진2에서 1st와 2nd를 반복, 3번 사진과 3', 4번 사진과 4'  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**4th. 출처 같은 사진은 비슷한 값이 나오게끔, 출처 다른 사진은 최대한 먼 값이 나오도록 학습시키는 기법**  

+**GPT**: 다음 단어를 예측하는 방식의 자기지도학습  
&nbsp;&nbsp;&nbsp;**BERT**: 문장 빈칸에 들어갈 단어 예측하는 방식의 자기지도학습  

Q & A  
Q. 레이블이란?  
A. 데이터에 대응하는 숫자들. 데이터에 대한 정답 또는 분류 결과.  
 

---
