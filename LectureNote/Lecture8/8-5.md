## 8-5. Dropout          
overfitting을 방지하기 위해..

> ### Dropout
: **`랜덤하게 노드를 가려보면서 학습`**  
&nbsp;&nbsp;-> 서로 다른 network 여러 개를 사용하여 학습하게 됨  
&nbsp;&nbsp;테스트 시에는 이것들을 **평균 내서 사용**  

**1st.** 적용시키고 싶은 layer에 **`dropout`** 적용  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**`dropout`**: 랜덤하게 선택된 노드를 일시적으로 탈락시킴  
**2nd.** 데이터가 통과할 때마다 살릴 노드를 다시 고른다.  

|Train Data|Test Data|
|:--:|:--:|
|일부 노드 활성화|모든 노드 활성화|
|p의 확률에 따라 활성화 여부가 달라짐|Dropout이 적용되었던 layer에 p 곱함|  

> #### Auto Encoder
: 자기 자신을 인코딩한다  

여기서 dropout를 적용하지 않았을 시, 노드들의 패턴을 구별하기 더 어려워져 특징적인 정보를 추출하지 못한다.  

---
