## 2-3. 선형 회귀(Linear Regression)  
> **선형 회귀**

입력과 출력 간의 관계(함수)를 **선형으로 놓고** 알아내는 것  
ax + b에서 **최적의 a와 b**를 알아내는 것  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;↳ **`loss`** 를 최소화하는 a, b  


### > **`Loss(L)`**  
> **1st.** 자신이 풀고 싶은 문제에 맞게 정의

예)  AI의 예측(ŷ)과 실제 수익(y)의 차이
<img src="https://github.com/user-attachments/assets/75d57d89-b687-4598-90f3-117e813c2fa6" alt="description" style="width:70%; height:auto;">  

하지만 only 합으로만 할 경우 옳지 않은 함수도 가능하게 됨  
따라서 아래의 방법들 사용  
```
TYPE1) MAE  
TYPE2) MSE
```
|MAE(Mean Absolute Error)|MSE(Mean Squared Error|
|:--:|:--:|
|오차 절댓값의 평균(or 합)|오차 제곱의 평균(or 합)|
|Outlier(이상치)가 있을 경우 유리||  

####    
> **2nd.** (a, b)의 값을 바꿔가며 L식에 대입하여 L이 최소가 되는 (a, b)를 찾음

(L은 a와 b에 대한 방정식)  
<img src="https://github.com/user-attachments/assets/6057d396-3aa5-4fe0-a96d-904fb6187424" alt="description" style="width:30%; height:auto;">  
  
하지만 이는 파라미터가 많아지면 불가능  
sol) **경사 하강법**

Q & A  
Q. 선형 회귀의 경우 파라미터가 두 개라서 일일히 a와 b를 대입해볼 수 있는 거라 하였다. 그렇다면 파라미터란?
A. 인공신경망에서 웨이트와 바이어스를 말한다.
  
---
