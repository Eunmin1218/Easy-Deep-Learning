## 6-4. MLE  
**`조건부 확률`**: 어떤 사건이 일어났다는 전제 하에 다른 사건이 일어날 확률   
**`Likehood`**: 어떤 것이 관측될 가능성  
<img src="https://github.com/user-attachments/assets/76b8e82b-69ff-4051-9235-dc25b80ddc61" style="width:40%; height:auto;">  
여기서 **likehood**값을 보고 공을 뽑은 주머니를 추정하는 것을 **`MLE`** 라고 할 수 있음  
  
> ### MLE(Maximun Likehood Estimation)
: 앞의 것(measurement)를 보고 뒤의 것을 알아낸다!  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;↳ **`likehood`** : 위에서 P(색|주)를 주머니의 함수로 본 것  
MSE와 BCE는 사실 둘 다 **MLE**  
  
이진 분류에서 **Likehood** : 

$$
 {q}_n^{y_n}({1-q}_n)^{1-y_n}
$$

**`P(y₁) = P(y₁|w)`** 이기 때문!  
(y₁에 대한 조건부 확률 값을 w의 함수로 본 것)  

따라서 label이 **베르누이 분포**를 따르기에

$$
  P(y_1 | w )= {q}_n^{y_n}({1-q}_n)^{1-y_n}
$$


> #### BCE vs MSE
1. **`BCE`** :
   - y₁을 **베르누이**로 가정  
   - 확률 q₁이 y₁과 가깝게 나오도록 학습   
2. **`MSE`** :
   - y₁을 **가우시안**으로 가정  
   - y₁을 가우시안으로 가정하고, y₁의 평균 ŷ₁을 y₁과 가깝게 나오도록 학습

<img src="https://github.com/user-attachments/assets/31a0a4bd-16f5-40de-9018-7e491dea3e3f" style="width:45%; height:auto;">  

 즉, **`적절한 분포가 상황에 따라 달랐기 때문`** 이다.  

+MAE의 경우? -> Laplacian 분포  

### 인공신경망은 MLE 기계다!  
  
Q&A  
Q. 베르누이 분포란?  
A. 성공과 실패로 이루어진 단일 시행의 확률을 나타내는 분포  

Q. NLL이란?  
A. 간단히 여기서 손실함수라 생각하기.  

---
